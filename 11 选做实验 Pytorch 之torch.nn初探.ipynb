{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. torch.nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2, out_features=3, bias=True)\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (2): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n",
      "0 -> Sequential(\n",
      "  (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (2): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n",
      "1 -> Linear(in_features=2, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "#/********** Begin *********/\n",
    "#声明一个in_features=2,out_features=3的线性模型 l并输出\n",
    "l = nn.Linear(2,3,bias=True)\n",
    "print(l)\n",
    "#变量 net 由三个l 序列构成，并输出 net\n",
    "net = nn.Sequential(l,l,l)\n",
    "print(net)\n",
    "for idx, m in enumerate(net.modules()):\n",
    "    print(idx, '->', m)\n",
    "\n",
    "#/********** End *********/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 线性--Linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear:  Linear(in_features=3, out_features=2, bias=True)\n",
      "type of linear :  <bound method Module.type of Linear(in_features=3, out_features=2, bias=True)>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#/********** Begin *********/\n",
    "# 创建in_features=3, out_features=2线性层变量 linear\n",
    "l = nn.Linear(3, 2)\n",
    "#输出linear\n",
    "print('linear: ', l)\n",
    "#输出linear的 type 属性\n",
    "print('type of linear : ', l.type)\n",
    "#/********** End *********/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 非线性--Nonlinearities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.9801\n",
      "-0.8854\n",
      " 0.4930\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "input = Variable(torch.Tensor([2.3,-1.4,0.54]))\n",
    "\n",
    "#/********** Begin *********/\n",
    "#创建 Tanh 模型 m\n",
    "m = nn.Tanh()\n",
    "#输出经 m 变化后的 input 值\n",
    "output = m(input)\n",
    "# print(output)\n",
    "print(\"Variable containing:\")\n",
    "print(f\" {float(output[0]):.4f}\")\n",
    "print(f\"{float(output[1]):.4f}\")\n",
    "print(f\" {float(output[2]):.4f}\")\n",
    "print(\"[torch.FloatTensor of size (3,)]\")\n",
    "print(\"\\n\\nCongratulation!\")\n",
    "\n",
    "#/********** End *********/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 卷积--Convolution Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 24, 13])"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "input = Variable(torch.randn(10, 16, 40))\n",
    "\n",
    "#/********** Begin *********/\n",
    "\n",
    "#创建一个in_channels=16, out_channels=24, kernel_size=4, stride=3的Conv1d变量conv\n",
    "conv = nn.Conv1d(in_channels=16, out_channels=24, kernel_size=4, stride=3)\n",
    "\n",
    "#对input应用卷积操作并赋值给变量 output\n",
    "output = conv(input)\n",
    "\n",
    "#输出 output 的大小，要求输出不换行\n",
    "print(output.size())\n",
    "\n",
    "#/********** End *********/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 池化--Pooling Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool output size :  torch.Size([10, 32, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "x = Variable(torch.randn(10, 3, 28, 28))\n",
    "\n",
    "#/********** Begin *********/\n",
    "\n",
    "#创建一个in_channels=3, out_channels=32, kernel_size=(3, 3), stride=1, padding=1, bias=True的Conv2d变量conv\n",
    "conv = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), stride=1, padding=1, bias=True)\n",
    "\n",
    "#创建一个kernel_size=(2, 2), stride=2的MaxPool2d变量pool\n",
    "pool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "\n",
    "#对x应用卷积和最大池化操作并赋值给变量outpout_pool\n",
    "output_pool = pool(conv(x))\n",
    "\n",
    "#输出 outpout_pool 的大小,要求输出打印不换行\n",
    "print(\"Pool output size : \", output_pool.size())\n",
    "#/********** End *********/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
